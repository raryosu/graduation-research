\section{はじめに}
クラスタリングとはデータを教師なし学習により任意の数のクラスタに分ける手法である．
クラスタリングはデータ解析，データマイニング，パターン認識など様々な分野で用いられる．
K-meansを始めとする多くのクラスタリング手法では，予めクラスタ数がわかっているものとして，
クラスタ数を指定しクラスタリングを行う．
しかし，データに対し最適なクラスタ数を指定しなければ，最適なクラスタリング結果を得ることはできないが，
一般にクラスタ数が事前にわかっているデータは少ない．
その為，クラスタ数が未知である場合にも，適切にクラスタ数を推定することは重要な課題となっている．

既存の手法の多くは，データが確率分布関数から生成されたと想定して，
その確率分布を生成するモデルを推定することにより，クラスタ数推定を行う．
クラスタ数推定を行う際，よく用いられるのが情報量規準と呼ばれれる指標である．
情報量規準とは簡単に言えば確率分布とデータの分布の当てはまり具合を表す．
その情報量基準は多くの研究者により様々なものが提案されている．
例えば，1973年に赤池が提案したAIC (Akaike Information Criterion) や，
Bayesの定理によって算出される事後確率を用いるBIC (Bayesian Information Criterion)が有名である．

しかし，どの情報量規準がどのようなデータに対し有効かは分かっていない．
そこで本研究では，クラスタ数推定に用いる情報量規準として最適なものを数値実験を通し明らかにする．

前期は，混合等方Gauss分布から生成されたデータをX-meansにより
クラスタ数推定およびクラスタリングを行い，AIC, cAIC, BICと呼ばれる情報量規準によるクラスタリングの性能の評価を行った．

第2章では，既存のクラスタリング手法であるK-meansのアルゴリズムの紹介を行う．

第3章では，本研究で利用するX-meansの理論の説明を行う．
まず，モデルと真の確率分布との近さを計る指標であるKullback-Leibler情報量について述べ，
それと最尤推定との情報量規準の関係性について詳しく述べる．
その後，X-meansの手法について述べる．

第4章では，本研究により得られた実験結果について述べる．

第5章では，本研究を通してのまとめおよび今後の課題について述べる．
