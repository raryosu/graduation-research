\section{結論}

本研究では，いくつかの情報量規準を分割停止規準として採用してX-meansでクラスタ数推定を行った．

まず，混合等方Gauss分布から生成したデータのクラスタ数推定を行った．
2次元空間における混合等方Gauss分布から生成したデータセットのクラスタ数推定においてはBICやcAICが，
3次元空間における混合等方Gauss分布から生成したデータセットのクラスタ数推定においてはBICが適していることがわかった．
2次元空間においてはAICを採用した場合，クラスタ数を過大に見積もってしまう問題が見られた．
AICは導出に漸近理論を用いているため，パラメータ数を過大に見積もるという問題点があり，
それに起因してクラスタ数を課題に見積もったと考えられる．
cAICはAICのこの問題を解決するために，漸近理論を用いずに導出された情報量規準である．
本研究でもcAICを用いることで，AICを用いた場合よりも非常に高い精度でクラスタ数を推定することが確認できた．
したがって，データ数が比較的少ない場合はcAICを情報量規準として採用することで，
AICよりもよい精度でクラスタ数推定ができるといえる．
しかし，cAICは3次元空間の等方Gauss分布のクラスタ数推定では2次元空間の等方Gauss分布のクラスタ数推定に比べ，
BICよりもより劣った結果となっている．
同一条件で2次元空間と3次元空間でクラスタリングを行ったため，後者のほうがデータが分布する空間が広い．
そのため，クラスタ同士の重なり合いが少なくなり，クラスタ数推定の精度がいずれも向上している．
等方Gauss分布をモデルとしたX-meansによるクラスタ数推定では，BICを分割停止規準として用いると
非常に精度良くクラスタ数推定を行うことができることがわかった．
したがって，混合等方Gauss分布により生成されたデータのクラスタリングを行う際は
等方Gauss分布をモデルとするX-meansの分割停止規準としてBICを採用することで適切なクラスタ数推定を行うことができるといえる．

実データ (MNIST) のクラスタ数推定を行った場合，いずれの情報量規準を分割停止規準を用いた場合も，
ほぼ同一の結果となり，等方Gauss分布をモデルとするX-meansでは適切なクラスタ数推定を行うことができないことがわかった．
% MNISTはどういう分布なんだろう...?
クラスタ数推定に失敗した原因は3つ考えられる．
1つは，データ自体が10のクラスタに分かれていないかもしれない点である．
手書き文字の場合，同一の数字でも様々な書き方が存在しているため，同一の数字の画像が1つのクラスタを形成しているとは限らない．
2つは，クラスタ推定をしやすくするための前処理をデータに対し施さなかった点である．
手書き画像は，線の太さも濃さも様々である．
そのような画像データの場合，同じ形の文字であっても，線の太さや濃さの違いでデータとしては全く別のものになってしまう．
3つは，MNISTにおいてクラスタ数推定，MNISTの分布が等方Gauss分布に従っていないことが要因と考えられる．
適切なクラスタ数推定を行うためには，他のモデルを用いるなどの工夫をする必要があると考えられる．
また，確率ベースではないクラスタ数推定を行う手法としてMean shiftによるクラスタリングも同様に行ったが，複数の確率密度関数の極大点を見つけることができず，適切なクラスタリング結果を得ることはできなかった．

以上の段落より，混合等方Gauss分布から生成される人工データのクラスタリングにはBICが最も適していることがわかった．
また，AICは少量のデータのクラスタ数推定には向かず，cAICを利用することで適切なクラスタ数推定を行うことができる．
実データのクラスタ数推定を行う際には，そのデータにあったモデルやクラスタ数推定の手法を採用する必要があり，
今後実データのクラスタ数を適切に推定するための手法を検討していく必要がある．
