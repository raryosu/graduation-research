\section{緒言}
クラスタリングとはデータを教師なし学習により任意の数のクラスタ（データのグループ）に分ける手法である．
クラスタリングはデータ解析，データマイニング，画像処理，パターン認識など様々な分野で用いられる．
$k$-meansを始めとする多くのクラスタリング手法では，予めクラスタ数がわかっているものとして，
クラスタ数を指定しクラスタリングを行う．
しかし，データに対し最適なクラスタ数を指定しなければ，最適なクラスタリング結果を得ることはできない．
それにも関わらず，一般にクラスタ数が事前にわかっているデータは少ない．
その為，クラスタ数が未知である場合に対しても，適切にクラスタ数を推定しクラスタリングを行うことは重要な課題となっている．

クラスタ数推定を行う手法の一つにX-meansがある．
X-meansは，データが混合等方Gauss分布から生成されたと想定して，
その確率分布のパラメータを推定することにより，クラスタ数推定を行う．
X-meansは情報量規準とよばれる，確率分布とデータの分布の当てはまり具合（モデルの良さ）を表す指標を用い，クラスタ数推定を行う．
その情報量基準は多くの研究者により様々なものが提案されている．
代表的なものに，1973年に赤池が提案したAIC (Akaike Information Criterion) や，
Bayesの定理によって算出される事後確率を用いるBIC (Bayesian Information Criterion) ，
AICの課題を解決したcAIC (Conditional Akaike Information Criterion) などがある．
一般にX-meansは，クラスタ数を決定する上で BIC を用いている．
しかし，クラスタ数推定において，どの情報量規準がどのようなデータに対し有効かは分かっていない．
そこで本研究では，クラスタ数推定に用いる情報量規準として最適なものを数値実験を通し明らかにする．

本研究では，AIC, cAIC, BICと呼ばれる情報量規準をそれぞれ用いたX-meansにより混合等方Gauss分布から生成されたデータ
および実データのクラスタ数推定およびクラスタリングを行った．
そして，どの情報量基準がクラスタ数推定に有効かを調査した．

本報告書の構成は次のとおりである．
第2章では，既存のクラスタリング手法である$k$-meansおよびMean shiftのアルゴリズムの紹介を行う．
第3章では，本研究で利用するX-meansの理論の説明を行う．
まず，モデルと真の確率分布との近さを計る指標である情報量基準の例としてKullback-Leibler情報量について述べ，
それと最尤推定との情報量規準の関係性について詳しく述べる．
その後，X-meansの手法について述べる．
第4章では，本研究により得られた実験結果について述べる．
第5章では，本研究を通してのまとめおよび今後の課題について述べる．
