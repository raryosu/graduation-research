# X-means

## X-meansとは

K-meansには3つの欠点がある．
1. 計算のスケーラビリティがよろしくない
2. クラスタ数をユーザが指定する必要がある
3. local minimumに収束することがある

X-meansは1, 2番目を解決し，3つ目に対する部分的救済をとる．

X-meansはクラスタ数を素早く求めることができる．
K-meansをそれぞれ実行し，よりデータにフィットするように現在のセントロイドを分割する．
分割決定はBICによって計算される．

## K-meansの手法

1. それぞれのデータに対して最も近いセントロイドを見つけてラベル付けする2
2. 再度それぞれのセントロイドの位置を推定する

K-meansはlocal minimumに陥りがちである．
また，実用的なデータセットに使うにはおそすぎるということも知られている．

焼きなまし法は，直接入力データの分割線を見つけ出す．
十分な統計量を持つ木構造は異常値を識別し，高速計算をするのに用いられる．

しかし，計算されたクラスタは多数のパラメータによる近似である．

最初のセンターは任意に選択される．
それが悪い選択であればパフォーマンスにも会にも大きな影響を与える．

## クラスタ数推定

### Model Searching

最初はKの値を小さくしておく．
そして，上限に達するまでセントロイドを増やしていく．
この過程においてセントロイドが良いスコアを収めたら，それは最終的な出力となる．

X-meansは2つの命令を完了するまで繰り返す．

1. パラメータを改善する
2. 構成を改善する
3. Kの最大値を越したら最もいいモデルを報告する．そうでなければ1にもどる

1の過程はシンプルである．従来のK-meansを実行して収束させることである．

2の過程は，どこにセントロイドを増やすべきかを見つけ出す過程である．
これは，いくつかのセントロイドを2つに分割することで達成する．
2つの戦略を立て，その後それらの強みを組み合わせ，弱点を回避することで
セントロイドをどのように分割するかを決めることができる．

#### 分割アイデア1

1つのセントロイドを選択し，新しいセントロイドを近くにつくる．
そしてK-meansを実行し，モデルスコアが良いかを見る．
もしよければ新しいセントドイドを受容し，だめなら元に戻す．
しかしこれはO(Kmax)の計算量を要する．

構造を改善するステップはX-meansが完了するまで実行する．
そしてこれはどうやって分割するに値するセントロイドを選ぶかという問に答える．

スコアが改善しない場合は？
すべてのセントロイドに対してこの手法を試してみるべきでしょう．
しかしK-meansによるテストを走らせることは
たったひとつのセントドイドを追加するにしてはコストが高すぎる．

#### 分割アイデア2

Gausian mixture modelのためのSPLITLOOPシステムを使う．

人工的な規準に従って重心の半分を選択するだけで，
その分割がどれほど有用であるかがわかる．

分割した後K-meansを走らせ，結果を見てオリジナルより良い結果を残しているかを見る．
良い結果であれば分割を受容する．

これは積極的な構造改善であり，計算量はたかだかO(logKmax)である，

構造改善ステップはX-meansが完了するまで続ける．
しかし，人工的な規準とはなんだろうか．
各クラスタの領域であろうか．セントロイドによる歪みだろうか．

さらに我々は1つまたは2つの分割を行う必要があるだろうが，
残りの分割がそうでない場合は改善の機会を逃すだろう．


